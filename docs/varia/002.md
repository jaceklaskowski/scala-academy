# Day 2 / May 17 (Tue)

## Live-Coding Session

A live-coding session of [Demo: Running Spark Examples on minikube](https://jaceklaskowski.github.io/spark-kubernetes-book/demo/running-spark-examples-on-minikube/) by Krzysiek.

### Invalid value: "TYPE=ssh"

During the session we faced the following issue that we eventually managed to sort out by reviewing the source code of Spark on Kubernetes (namely [org.apache.spark.deploy.k8s.submit.KubernetesClientUtils]({{ spark.github }}/resource-managers/kubernetes/core/src/main/scala/org/apache/spark/deploy/k8s/submit/KubernetesClientUtils.scala)).

```text
22/05/17 09:26:36 INFO SparkKubernetesClientFactory: Auto-configuring K8S client using current context from users K8S config file
22/05/17 09:26:38 INFO KerberosConfDriverFeatureStep: You have not specified a krb5.conf file locally or via a ConfigMap. Make sure that you have the krb5.conf locally on the driver image.
22/05/17 09:26:39 INFO KubernetesClientUtils: Spark configuration files loaded from Some(/home/adform/spark/conf) : spark-env.sh
Exception in thread "main" io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: POST at: https://127.0.0.1:56811/api/v1/namespaces/spark-demo/configmaps. Message: ConfigMap "a1-a0a2c280d0e95f2a-hadoop-config" is invalid: data[TYPE=ssh]: Invalid value: "TYPE=ssh": a valid config key must consist of alphanumeric characters, '-', '_' or '.' (e.g. 'key.name',  or 'KEY_NAME',  or 'key-name', regex used for validation is '[-._a-zA-Z0-9]+'). Received status: Status(apiVersion=v1, code=422, details=StatusDetails(causes=[StatusCause(field=data[TYPE=ssh], message=Invalid value: "TYPE=ssh": a valid config key must consist of alphanumeric characters, '-', '_' or '.' (e.g. 'key.name',  or 'KEY_NAME',  or 'key-name', regex used for validation is '[-._a-zA-Z0-9]+'), reason=FieldValueInvalid, additionalProperties={})], group=null, kind=ConfigMap, name=a1-a0a2c280d0e95f2a-hadoop-config, retryAfterSeconds=null, uid=null, additionalProperties={}), kind=Status, message=ConfigMap "a1-a0a2c280d0e95f2a-hadoop-config" is invalid: data[TYPE=ssh]: Invalid value: "TYPE=ssh": a valid config key must consist of alphanumeric characters, '-', '_' or '.' (e.g. 'key.name',  or 'KEY_NAME',  or 'key-name', regex used for validation is '[-._a-zA-Z0-9]+'), metadata=ListMeta(_continue=null, remainingItemCount=null, resourceVersion=null, selfLink=null, additionalProperties={}), reason=Invalid, status=Failure, additionalProperties={}).
        at io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:639)
        at io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:578)
        at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:543)
        at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:504)
        at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleCreate(OperationSupport.java:292)
        at io.fabric8.kubernetes.client.dsl.base.BaseOperation.handleCreate(BaseOperation.java:893)
        at io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:357)
        at io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:86)
        at io.fabric8.kubernetes.client.handlers.core.v1.ConfigMapHandler.create(ConfigMapHandler.java:39)
        at io.fabric8.kubernetes.client.handlers.core.v1.ConfigMapHandler.create(ConfigMapHandler.java:25)
        at io.fabric8.kubernetes.client.utils.CreateOrReplaceHelper.lambda$createOrReplaceItem$0(CreateOrReplaceHelper.java:77)
        at io.fabric8.kubernetes.client.utils.CreateOrReplaceHelper.createOrReplace(CreateOrReplaceHelper.java:56)
        at io.fabric8.kubernetes.client.utils.CreateOrReplaceHelper.createOrReplaceItem(CreateOrReplaceHelper.java:91)
        at io.fabric8.kubernetes.client.dsl.internal.NamespaceVisitFromServerGetWatchDeleteRecreateWaitApplicableListImpl.createOrReplaceOrDeleteExisting(NamespaceVisitFromServerGetWatchDeleteRecreateWaitApplicableListImpl.java:454)
        at io.fabric8.kubernetes.client.dsl.internal.NamespaceVisitFromServerGetWatchDeleteRecreateWaitApplicableListImpl.createOrReplace(NamespaceVisitFromServerGetWatchDeleteRecreateWaitApplicableListImpl.java:297)
        at io.fabric8.kubernetes.client.dsl.internal.NamespaceVisitFromServerGetWatchDeleteRecreateWaitApplicableListImpl.createOrReplace(NamespaceVisitFromServerGetWatchDeleteRecreateWaitApplicableListImpl.java:66)
        at org.apache.spark.deploy.k8s.submit.Client.run(KubernetesClientApplication.scala:150)
        at org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.$anonfun$run$4(KubernetesClientApplication.scala:220)
        at org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.$anonfun$run$4$adapted(KubernetesClientApplication.scala:214)
        at org.apache.spark.util.Utils$.tryWithResource(Utils.scala:2713)
        at org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.run(KubernetesClientApplication.scala:214)
        at org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.start(KubernetesClientApplication.scala:186)
        at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:955)
        at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)
        at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)
        at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)
        at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1043)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1052)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
```

The issue was an environment variable that pointed out at a directory with configuration files that should not have been loaded. Call it a _misconfiguration_ of Spark on Kubernetes.

## Scala Exercises

### Using PATH Environment Variable

Write a function that accepts a `path` (of type `String`) and returns a `Boolean` value whether the path is in the `PATH` environment variable or not. Use `sys.env`.

### File Directories

Write a function that accepts a file name (`String`) and returns the directories it is in (in `PATH` environment variable). The function should return all the paths with the file.

Review a solution in [solutions/path-utils]({{ book.github }}/solutions/path-utils) project.

This project uses the following:

1. [ScalaTest](https://www.scalatest.org/)
1. [scalamock](https://scalamock.org/)
1. Higher-order functions for OS-dependent features (e.g., `sys.env` and `java.io.File`)
