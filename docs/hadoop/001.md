# Day 1 / May 9 (Mon)

## Introduction to Apache Hadoop {{ hadoop.version }}

1. [Apache Hadoop](https://hadoop.apache.org/)
1. [Release 3.3.2 available](https://hadoop.apache.org/release/3.3.2.html)
1. [Hadoop Commands Guide]({{ hadoop.docs }}/hadoop-project-dist/hadoop-common/CommandsManual.html)
1. [FileSystem Shell]({{ hadoop.docs }}/hadoop-project-dist/hadoop-common/FileSystemShell.html)
1. [The Hadoop FileSystem API Definition]({{ hadoop.docs }}/hadoop-project-dist/hadoop-common/filesystem/index.html)

## Exercise: Setting Up Hadoop Cluster

1. [Hadoop: Setting up a Single Node Cluster]({{ hadoop.docs }}/hadoop-project-dist/hadoop-common/SingleCluster.html) which shows you how to set up a single-node Hadoop installation

## Introduction to HDFS

Read the following documents:

1. [Architecture]({{ hadoop.docs }}/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html)
1. [Users Guide]({{ hadoop.docs }}/hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html)
1. [Commands Guide]({{ hadoop.docs }}/hadoop-project-dist/hadoop-hdfs/HDFSCommands.html)

## Exercise: Spark SQL and HDFS

Create a Spark SQL application that loads CSV files from a HDFS directory

1. Use `hdfs://` URI
1. Review [Load Spark data locally Incomplete HDFS URI](https://stackoverflow.com/q/29079396/1305344) et al.

## Code Reviews

1. https://github.com/szczepanja/file-listing
1. https://github.com/1Gize/list-files-in-folder
1. https://github.com/JKulczynski/Docker-CommandLine-App
1. https://github.com/rafalkac02/directory-traverser
