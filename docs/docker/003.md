# Day 3 / May 6 (Fri)

Today, we focus on the following:

1. Developing dockerized Spark and Kafka Streams application
1. Contributing to a git repo on Github (using pull requests and issues)

## In the Morning

Reviewing [pull requests](https://github.com/jaceklaskowski/scala-academy-sandbox/pulls) to `scala-academy-sandbox` repo.

## Exercise 1

1. Create a dockerized Scala command-line application that accepts a directory to list files from

    ```console
    docker run [imageName] /path/to/a/directory
    ```

## Exercise 2

It's a follow-up exercise to [Exercise 1](#exercise-1).

Read [Manage application data](https://docs.docker.com/storage/) and mount a directory outside the Docker image to list files from.

## Exercise 3

1. Create a dockerized Spark application that loads files from one or more directories
    1. Use `local[*]` master URL
    1. Use scopt to handle command line

## Docker Compose

1. [Overview of Docker Compose](https://docs.docker.com/compose/)
1. [Get started with Docker Compose](https://docs.docker.com/compose/gettingstarted/)

## Exercise: Dockerized Kafka Cluster

Running a dockerized Kafka Cluster using [Confluent Platform](https://docs.confluent.io/platform/current/quickstart/ce-docker-quickstart.html) (and Docker Compose).

## Exercise: Dockerized Kafka Streams Application

Create and run a dockerized Kafka Streams application.

**TIP**: Use [Confluent Platform](https://docs.confluent.io/platform/current/quickstart/ce-docker-quickstart.html) (and Docker Compose).
