# Day 8 / Apr 13 (Wed)

Continuing the journey into the land of Spark Structured Streaming.

## Morning Exercise

1. Create a brand new project in IntelliJ IDEA
1. Use `rate` data source as the source
1. Use `foreach` to write data out
    1. Create a file for the records of a batch
    1. Open and close the file before and after `process`ing the records
1. Run the application from command line using `spark-submit`

## Theory

1. [Joins](https://jaceklaskowski.github.io/spark-workshop/slides/spark-sql-joins.html#/home)
1. web UI

## Exercises

1. [Selecting the most important rows per assigned priority](https://jaceklaskowski.github.io/spark-workshop/exercises/sql/selecting-the-most-important-rows-per-assigned-priority.html)
1. [Exercise: Reverse-engineering Dataset.show Output](https://jaceklaskowski.github.io/spark-workshop/exercises/spark-sql-exercise-Reverse-engineering-Dataset-show-Output.html)
1. [Exercise: Specifying Table and SQL Query on Command Line](https://jaceklaskowski.github.io/spark-workshop/exercises/spark-sql-exercise-Specifying-Table-and-SQL-Query-on-Command-Line.html)
