# Day 7 / Apr 12 (Tue)

Continuing the journey into the land of Spark Structured Streaming.

## Morning Exercise

[Exercise: Your First Standalone Structured Streaming Application](https://jaceklaskowski.github.io/spark-workshop/exercises/spark-structured-streaming-exercise-Your-First-Standalone-Structured-Streaming-Application.html)

1. Create a brand new project in IntelliJ IDEA
1. An input directory to read files from should be defined on command line (`args(0)`)
    1. (advanced/optional) Use scopt for the input directory
1. Run the application from command line using `spark-submit`

## Theory

1. [Spark Structured Streaming](https://jaceklaskowski.github.io/spark-workshop/slides/spark-structured-streaming.html#/home)

## Exercises

1. [Exercise: Finding Most Common Non-null Prefix per Group (Occurences)](https://jaceklaskowski.github.io/spark-workshop/exercises/spark-sql-exercise-Finding-Most-Common-Non-null-Prefix-Occurences-per-Group.html)
1. [Exercise: Finding First Non-Null Value per Group](https://jaceklaskowski.github.io/spark-workshop/exercises/spark-sql-exercise-Finding-First-Non-Null-Value-per-Group.html)

## Homework

1. Read the scaladoc of [org.apache.spark.sql.streaming.StreamingQuery]({{spark.docs}}/api/scala/org/apache/spark/sql/streaming/StreamingQuery.html)
