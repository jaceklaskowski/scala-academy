# Day 7 / Apr 12 (Tue)

Continuing the journey into the land of Spark Structured Streaming.

## Morning Exercise

[Exercise: Your First Standalone Structured Streaming Application](https://jaceklaskowski.github.io/spark-workshop/exercises/spark-structured-streaming-exercise-Your-First-Standalone-Structured-Streaming-Application.html)

1. Create a brand new project in IntelliJ IDEA
1. An input directory to read files from should be defined on command line (`args(0)`)
    1. (advanced/optional) Use scopt for the input directory
1. Run the application from command line using `spark-submit`

## Theory

### Slides

1. [Spark Structured Streaming](https://jaceklaskowski.github.io/spark-workshop/slides/spark-structured-streaming.html#/home)
1. [Joins](https://jaceklaskowski.github.io/spark-workshop/slides/spark-sql-joins.html#/home)

## Exercises

1. [Exercise: Finding Most Common Non-null Prefix per Group (Occurences)](https://jaceklaskowski.github.io/spark-workshop/exercises/spark-sql-exercise-Finding-Most-Common-Non-null-Prefix-Occurences-per-Group.html)
1. [Exercise: Finding First Non-Null Value per Group](https://jaceklaskowski.github.io/spark-workshop/exercises/spark-sql-exercise-Finding-First-Non-Null-Value-per-Group.html)
1. [Selecting the most important rows per assigned priority](https://jaceklaskowski.github.io/spark-workshop/exercises/sql/selecting-the-most-important-rows-per-assigned-priority.html)
1. [Exercise: Reverse-engineering Dataset.show Output](https://jaceklaskowski.github.io/spark-workshop/exercises/spark-sql-exercise-Reverse-engineering-Dataset-show-Output.html)
1. [Exercise: Specifying Table and SQL Query on Command Line](https://jaceklaskowski.github.io/spark-workshop/exercises/spark-sql-exercise-Specifying-Table-and-SQL-Query-on-Command-Line.html)
